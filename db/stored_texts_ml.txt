Test 7 — Conceptual Consolidation & Expansion Section A: Objective Questions (15) (MCQ or True / False as stated) Q1.
(MCQ) In linear regression, which situation causes coefficient estimates to be consistent but inefficient?
Q2.
(True / False) If the Gauss–Markov assumptions hold, the OLS estimator has minimum variance among all unbiased linear estimators.
Q3.
(MCQ) Which statement best explains why logistic regression coefficients are interpretable?
Q4.
(MCQ) Which property of entropy makes it more sensitive to small class probabilities?
Q5.
(True / False) A decision tree with zero training error necessarily has low bias.
Q6.
(MCQ) Which change most directly increases the bias of an SVM classifier?
Q7.
(MCQ) What is the primary reason cosine similarity is often preferred over Euclidean distance in text-based k-NN?
Q8.
(True / False) In PCA, orthogonality of principal components guarantees statistical independence.
Q9.
(MCQ) Which scenario most strongly suggests PCA should NOT be applied before modeling?
Q10.
(MCQ) Which statement about Naive Bayes probability estimates is most accurate?
Q11.
(True / False) k-means clustering minimizes within-cluster variance but does not explicitly maximize between-cluster separation.
Q12.
(MCQ) Which transformation is most appropriate when variance increases with the level of the time series?
Q13.
(True / False) A time series can be stationary but still difficult to forecast accurately.
Q14.
(MCQ) Which validation mistake most commonly leads to information leakage in time-series modeling?
Q15.
(True / False) A model with lower bias is always preferable to a model with slightly higher bias but much lower variance.
Section B: Interview / Applied Reasoning (3) Q16.
Why can probability calibration matter more than raw accuracy in decision-making systems?
Q17.
Why do distance-based models degrade more rapidly than tree-based models under feature noise?
Q18.
Why is it dangerous to evaluate models only on a single train–test split, even when test performance looks strong?
Section C: Tough / Deep Reasoning (2) Q19.
(Bias–Variance / Causality) How can a model show decreasing validation error while becoming less causally reliable?
Q20.
(Time Series — New Angle) Why does walk-forward validation often give more pessimistic performance estimates than random cross-validation, and why is that pessimism desirable?
Test 6 — Machine Learning Mastery Check Section A: Objective (15 questions) Q1.
(MCQ) Which condition guarantees that the ordinary least squares estimator is unbiased?
(True / False) Adding a perfectly collinear feature to a linear regression model changes the predictions.
(MCQ) Which statement best explains why logistic regression outputs calibrated probabilities?
(MCQ) Which of the following most increases the variance of a decision tree?
(True / False) Bagging primarily reduces variance rather than bias.
(MCQ) In an SVM, which parameter most directly controls overfitting?
(MCQ) Why does k-NN typically fail in very high-dimensional spaces?
(True / False) PCA guarantees improved classification accuracy if enough variance is preserved.
(MCQ) Which is the main practical disadvantage of Naive Bayes?
(MCQ) Which clustering method can discover arbitrarily shaped clusters?
(True / False) Feature scaling changes the structure of a decision tree.
(MCQ) Which time-series transformation is primarily used to remove deterministic trends?
(True / False) A stationary series must have constant mean, variance, and autocovariance over time.
(MCQ) Which evaluation approach is most appropriate for time-series models?
(True / False) Increasing model complexity always improves generalization when training data is large.
Section B: Interview Questions (3) Q16.
Why does regularization improve model reliability even when training accuracy decreases?
Why do ensemble methods often outperform single models in real-world ML systems?
Why is interpretability sometimes more important than raw accuracy in enterprise ML deployments?
Section C: Tough Questions (2) Q19.
How can two models with identical ROC-AUC values behave very differently in production?
Why does multi-step time-series forecasting amplify uncertainty even for a stationary process?
Test 5 — Machine Learning Conceptual Review Section A: Objective Questions (15 questions) (MCQ or True/False as stated) Q1.
(MCQ) In linear regression, which situation most directly violates the assumption required for unbiased coefficient estimates?
(True / False) Standardizing features changes the optimal solution of ordinary least squares linear regression.
(MCQ) Which statement best explains why logistic regression is still considered a linear model?
(MCQ) Which split criterion in decision trees is generally more sensitive to class imbalance?
(True / False) A k-NN classifier with very small k typically has low bias and high variance.
(MCQ) In an SVM, which data points directly determine the position of the decision boundary?
(MCQ) Why do linear models often perform well for text classification tasks?
(True / False) Using an RBF kernel guarantees better performance than a linear kernel in high-dimensional feature spaces.
(MCQ) Which statement best captures a limitation of PCA when used before supervised learning?
(True / False) If the first few principal components explain 95% of the variance, the remaining components are always irrelevant for prediction.
(MCQ) Which metric is most misleading on a highly imbalanced classification dataset?
(MCQ) Which clustering algorithm explicitly assumes spherical clusters of similar size?
(True / False) Naive Bayes often performs surprisingly well on text data despite its strong independence assumptions.
(MCQ) Why must time-series data generally not be split randomly for model evaluation?
(True / False) Increasing model complexity always reduces bias, regardless of data quality.
Section B: Interview-Style Conceptual Questions (3 questions) Q16.
Why can a simpler linear model sometimes outperform a more complex model in real-world production systems, even when training data is abundant?
Why is accuracy often an inappropriate evaluation metric for real-world classification problems, and what kinds of errors does it hide?
Why are tree-based models typically less sensitive to feature scaling, skewness, and monotonic transformations than linear or distance-based models?
Section C: Tough / Deep Reasoning Questions (2 questions) Q19.
(Tough – Bias–Variance & Generalization) Can two models with very similar training and validation performance still differ significantly in long-term real-world reliability?
Explain the mechanisms that cause this.
(Tough – Time Series) Why does forecast uncertainty increase with prediction horizon even when the model is well specified and the series is stationary?
ML Concept Refresh – Test 4 Section A: Core Assessment (15 Questions) Q1.
(MCQ – Linear Regression) Which situation most directly leads to biased coefficient estimates in linear regression?
(True / False – Linear Regression) Adding an irrelevant feature to a linear regression model always increases training error.
(MCQ – Logistic Regression) Which property makes log-loss suitable for probabilistic classification models?
(MCQ – Decision Trees) Why are decision trees considered high-variance models?
(True / False – Decision Trees) Pre-pruning a decision tree is a bias-increasing, variance-reducing technique.
(MCQ – SVM Geometry) Which data points influence the position of the SVM decision boundary?
(MCQ – Kernel Choice) Why does a linear kernel often outperform non-linear kernels in text classification?
(True / False – SVM Regularization) Increasing the value of C in a soft-margin SVM generally reduces the margin width.
(MCQ – PCA) Which statement best explains why PCA can hurt supervised learning performance?
(True / False – PCA) If the first two principal components explain 95% of the variance, using only those two is always optimal.
(MCQ – Naive Bayes) Which situation most strongly violates the Naive Bayes independence assumption?
(MCQ – KNN) Why is feature scaling critical for KNN?
(True / False – Clustering) DBSCAN can fail when clusters have significantly different densities.
(MCQ – Time Series) Which condition must hold for ARMA models to be valid without differencing?
(True / False – Bias & Variance) Increasing model complexity always decreases bias, regardless of data quality.
Why is R² often misleading when comparing models with different numbers of features?
Why do distance-based algorithms struggle more with high-dimensional data than tree-based models?
What practical signs suggest that a model is overfitting, even before looking at test metrics?
Section C: Tough / Edge Questions (2) Q19.
(Tough – Conceptual) Can two models have identical bias–variance profiles but very different real-world performance?
Explain.
(Tough – Time Series) Why does increasing the forecast horizon generally reduce confidence in predictions, even if the model is well specified?
ML Concept Refresh – Test 3 Section A: Core Assessment (15 Questions) Q1.
(MCQ – Linear Regression) Which situation most directly violates the assumption of independence in linear regression?
(True / False – Linear Regression) Centering features can change the interpretation of the intercept without changing the fitted values.
(MCQ – Logistic Regression) Why is log-loss preferred over accuracy during logistic regression training?
(MCQ – Decision Trees) Which property of Gini impurity causes it to stop splitting earlier than entropy?
(True / False – Decision Trees) A fully grown decision tree typically has low bias and high variance.
(MCQ – SVM Regularization) In soft-margin SVM, increasing parameter C primarily does what?
(MCQ – Kernel Choice) Why can RBF kernels perform poorly on very high-dimensional sparse data?
(True / False – SVM Geometry) Support vectors are the data points that lie exactly on the margin boundaries.
(MCQ – PCA) Which effect of PCA most directly helps linear models?
(True / False – PCA Usage) PCA can reduce overfitting even when classification accuracy decreases.
(MCQ – Naive Bayes) Which assumption allows Naive Bayes to scale well to high-dimensional data?
(MCQ – KNN) Why does KNN performance often degrade as the number of dimensions increases?
(True / False – Clustering) Hierarchical clustering always requires the number of clusters to be specified in advance.
(MCQ – Time Series) Why is differencing commonly applied before fitting ARIMA models?
(True / False – Bias & Variance) Bagging primarily reduces variance without significantly increasing bias.
Why is cross-validation not straightforward for time series data?
How does regularization influence the bias–variance tradeoff?
Why do tree-based models often outperform linear models on tabular data?
(Tough – Conceptual) Can increasing model complexity ever increase bias?
Explain with reasoning.
(Tough – Time Series) Why can a model with excellent one-step-ahead forecasts perform poorly for multi-step forecasting?
ML Concept Refresh – Test 2 Section A: Core Assessment (15 Questions) Q1.
(MCQ – Logistic Regression) Which statement is most accurate about the coefficients in logistic regression?
(True / False – Logistic Regression) A logistic regression model can have a linear decision boundary even though it uses a non-linear sigmoid function.
(MCQ – Linear Regression Assumptions) Which issue is most directly caused by multicollinearity?
(MCQ – Decision Trees) Why does entropy tend to favor deeper trees than Gini impurity?
(True / False – Decision Trees) Pruning a decision tree generally increases bias while reducing variance.
(MCQ – SVM Margin) What does maximizing the margin in SVM primarily achieve?
(MCQ – Kernel Choice) In which scenario is a linear SVM most likely to outperform an RBF SVM?
(True / False – Kernels) The kernel trick explicitly computes feature mappings into higher dimensions.
(MCQ – PCA) Which of the following statements about PCA is correct?
(True / False – PCA & Scaling) Feature scaling is necessary before applying PCA.
(MCQ – Naive Bayes) Why does Naive Bayes often work well even when the independence assumption is violated?
(MCQ – KNN) Which factor most strongly affects KNN performance as dataset size increases?
(True / False – Clustering) K-means clustering assumes clusters are convex and roughly equal in size.
(MCQ – Time Series Basics) Which statement best distinguishes time series data from standard regression data?
(True / False – Bias & Variance) Adding regularization to a model generally increases bias and decreases variance.
Why might a simple linear model outperform a complex model on real-world data?
Explain why accuracy is often a misleading metric for imbalanced classification problems.
Why is PCA considered an unsupervised technique even when used in supervised learning pipelines?
(Tough – Conceptual) You train a model with very low training error and very low test error.
Can such a model still have high bias?
Explain your reasoning.
(Tough – Time Series Intuition) Why does random train–test splitting often fail for time series data, even if the model and metrics are correct?
ML Concept Refresh – Test 1 Section A: Core Assessment (15 Questions) (MCQ + True/False; read carefully — some are subtle) Q1.
(MCQ – Linear Regression) Which assumption of linear regression is most directly violated when residuals show a funnel-shaped pattern?
(True / False – Linear vs Logistic Regression) Logistic regression minimizes mean squared error, similar to linear regression, but with a sigmoid output layer.
(MCQ – Logistic Regression) Which statement best explains why logistic regression uses log-odds?
(MCQ – Decision Trees) Which split criterion is more sensitive to class imbalance?
(True / False – Decision Trees) Increasing tree depth always reduces both bias and variance.
(MCQ – SVM) In a hard-margin SVM, what happens if the data is not linearly separable?
(MCQ – SVR) In Support Vector Regression, what does the ε (epsilon) parameter control?
(True / False – SVM Kernels) Using a non-linear kernel always improves SVM performance over a linear kernel.
(MCQ – PCA) PCA primarily seeks directions that maximize: Q10.
(True / False – PCA vs LDA) PCA can use class labels during dimensionality reduction, while LDA cannot.
(MCQ – Naive Bayes) Naive Bayes performs surprisingly well on high-dimensional text data mainly because: Q12.
(MCQ – KNN) Which change will most directly increase variance in a KNN classifier?
(True / False – Clustering) DBSCAN can identify clusters of arbitrary shape and automatically detects noise.
(MCQ – Time Series) Which technique is most appropriate to remove a deterministic trend from a time series?
(True / False – Bias & Variance) High bias models are typically complex models that overfit the training data.
How would you explain the bias–variance tradeoff to a non-technical stakeholder using a real-world analogy?
Why do tree-based models typically not require feature scaling, whereas KNN and SVM do?
PCA improves model performance in some cases but degrades it in others.
Explain why.
(Tough – Conceptual) You apply PCA before logistic regression and observe lower accuracy but better generalization on unseen data.
How is this possible?
(Tough – Time Series) A time series is stationary according to ADF test, but forecasts are consistently poor.
Give two non-obvious reasons why this can happen.
